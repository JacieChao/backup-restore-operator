{"apiVersion":"management.cattle.io/v3","kind":"RkeAddon","metadata":{"creationTimestamp":"2020-06-25T21:39:38Z","generation":1,"labels":{"backupper.cattle.io/old-uid":"361e3f20-dadb-4a08-9da9-5ef2100bdd89","cattle.io/creator":"norman"},"name":"calico-v1.13","namespace":"cattle-global-data","resourceVersion":"2350","selfLink":"/apis/management.cattle.io/v3/namespaces/cattle-global-data/rkeaddons/calico-v1.13"},"template":"\n{{if eq .RBACConfig \"rbac\"}}\n## start rbac here\n\n# Include a clusterrole for the calico-node DaemonSet,\n# and bind it to the calico-node serviceaccount.\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: calico-node\nrules:\n  # The CNI plugin needs to get pods, nodes, and namespaces.\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - nodes\n      - namespaces\n    verbs:\n      - get\n  - apiGroups: [\"\"]\n    resources:\n      - endpoints\n      - services\n    verbs:\n      # Used to discover service IPs for advertisement.\n      - watch\n      - list\n      # Used to discover Typhas.\n      - get\n  - apiGroups: [\"\"]\n    resources:\n      - nodes/status\n    verbs:\n      # Needed for clearing NodeNetworkUnavailable flag.\n      - patch\n      # Calico stores some configuration information in node annotations.\n      - update\n  # Watch for changes to Kubernetes NetworkPolicies.\n  - apiGroups: [\"networking.k8s.io\"]\n    resources:\n      - networkpolicies\n    verbs:\n      - watch\n      - list\n  # Used by Calico for policy information.\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - namespaces\n      - serviceaccounts\n    verbs:\n      - list\n      - watch\n  # The CNI plugin patches pods/status.\n  - apiGroups: [\"\"]\n    resources:\n      - pods/status\n    verbs:\n      - patch\n  # Calico monitors various CRDs for config.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - globalfelixconfigs\n      - felixconfigurations\n      - bgppeers\n      - globalbgpconfigs\n      - bgpconfigurations\n      - ippools\n      - globalnetworkpolicies\n      - globalnetworksets\n      - networkpolicies\n      - clusterinformations\n      - hostendpoints\n    verbs:\n      - get\n      - list\n      - watch\n  # Calico must create and update some CRDs on startup.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - ippools\n      - felixconfigurations\n      - clusterinformations\n    verbs:\n      - create\n      - update\n  # Calico stores some configuration information on the node.\n  - apiGroups: [\"\"]\n    resources:\n      - nodes\n    verbs:\n      - get\n      - list\n      - watch\n  # These permissions are only requried for upgrade from v2.6, and can\n  # be removed after upgrade or on fresh installations.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - bgpconfigurations\n      - bgppeers\n    verbs:\n      - create\n      - update\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: calico-node\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: calico-node\nsubjects:\n- kind: ServiceAccount\n  name: calico-node\n  namespace: kube-system\n- apiGroup: rbac.authorization.k8s.io\n  kind: Group\n  name: system:nodes\n{{end}}\n## end rbac here\n\n---\n# This ConfigMap is used to configure a self-hosted Calico installation.\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: calico-config\n  namespace: kube-system\ndata:\n  # To enable Typha, set this to \"calico-typha\" *and* set a non-zero value for Typha replicas\n  # below.  We recommend using Typha if you have more than 50 nodes. Above 100 nodes it is\n  # essential.\n  typha_service_name: \"none\"\n  # Configure the Calico backend to use.\n  calico_backend: \"bird\"\n\n  # Configure the MTU to use\n{{- if .MTU }}\n{{- if ne .MTU 0 }}\n  veth_mtu: \"{{.MTU}}\"\n{{- end}}\n{{- else }}\n  veth_mtu: \"1440\"\n{{- end}}\n\n  # The CNI network configuration to install on each node.  The special\n  # values in this config will be automatically populated.\n  cni_network_config: |-\n    {\n      \"name\": \"k8s-pod-network\",\n      \"cniVersion\": \"0.3.0\",\n      \"plugins\": [\n        {\n          \"type\": \"calico\",\n          \"log_level\": \"WARNING\",\n          \"datastore_type\": \"kubernetes\",\n          \"nodename\": \"__KUBERNETES_NODE_NAME__\",\n          \"mtu\": __CNI_MTU__,\n          \"ipam\": {\n            \"type\": \"host-local\",\n            \"subnet\": \"usePodCidr\"\n          },\n          \"policy\": {\n              \"type\": \"k8s\"\n          },\n          \"kubernetes\": {\n              \"kubeconfig\": \"{{.KubeCfg}}\"\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"snat\": true,\n          \"capabilities\": {\"portMappings\": true}\n        }\n      ]\n    }\n---\n\n# This manifest installs the calico/node container, as well\n# as the Calico CNI plugins and network config on\n# each master and worker node in a Kubernetes cluster.\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: calico-node\n  namespace: kube-system\n  labels:\n    k8s-app: calico-node\nspec:\n  selector:\n    matchLabels:\n      k8s-app: calico-node\n  updateStrategy:\n{{if .UpdateStrategy}}\n{{ toYaml .UpdateStrategy | indent 4}}\n{{else}}\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n{{end}}\n  template:\n    metadata:\n      labels:\n        k8s-app: calico-node\n      annotations:\n        # This, along with the CriticalAddonsOnly toleration below,\n        # marks the pod as a critical add-on, ensuring it gets\n        # priority scheduling and that its resources are reserved\n        # if it ever gets evicted.\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                - key: beta.kubernetes.io/os\n                  operator: NotIn\n                  values:\n                    - windows\n      hostNetwork: true\n{{if .NodeSelector}}\n      nodeSelector:\n      {{ range $k, $v := .NodeSelector }}\n        {{ $k }}: \"{{ $v }}\"\n      {{ end }}\n{{end}}\n      tolerations:\n        # Make sure calico-node gets scheduled on all nodes.\n        - effect: NoSchedule\n          operator: Exists\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - effect: NoExecute\n          operator: Exists\n      serviceAccountName: calico-node\n      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a \"force\n      # deletion\": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.\n      terminationGracePeriodSeconds: 0\n      initContainers:\n        # This container installs the Calico CNI binaries\n        # and CNI network config file on each node.\n        - name: install-cni\n          image: {{.CNIImage}}\n          command: [\"/install-cni.sh\"]\n          env:\n            # Name of the CNI config file to create.\n            - name: CNI_CONF_NAME\n              value: \"10-calico.conflist\"\n            # The CNI network config to install on each node.\n            - name: CNI_NETWORK_CONFIG\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: cni_network_config\n            # Set the hostname based on the k8s node name.\n            - name: KUBERNETES_NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # CNI MTU Config variable\n            - name: CNI_MTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # Prevents the container from sleeping forever.\n            - name: SLEEP\n              value: \"false\"\n          volumeMounts:\n            - mountPath: /host/opt/cni/bin\n              name: cni-bin-dir\n            - mountPath: /host/etc/cni/net.d\n              name: cni-net-dir\n      containers:\n        # Runs calico/node container on each Kubernetes node.  This\n        # container programs network policy and routes on each\n        # host.\n        - name: calico-node\n          image: {{.NodeImage}}\n          env:\n            # Use Kubernetes API as the backing datastore.\n            - name: DATASTORE_TYPE\n              value: \"kubernetes\"\n            # Typha support: controlled by the ConfigMap.\n            - name: FELIX_TYPHAK8SSERVICENAME\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: typha_service_name\n            # Wait for the datastore.\n            - name: WAIT_FOR_DATASTORE\n              value: \"true\"\n            # Set based on the k8s node name.\n            - name: NODENAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # Choose the backend to use.\n            - name: CALICO_NETWORKING_BACKEND\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: calico_backend\n            # Cluster type to identify the deployment type\n            - name: CLUSTER_TYPE\n              value: \"k8s,bgp\"\n            # Auto-detect the BGP IP address.\n            - name: IP\n              value: \"autodetect\"\n            # Enable IPIP\n            - name: CALICO_IPV4POOL_IPIP\n              value: \"Always\"\n            # Set MTU for tunnel device used if ipip is enabled\n            - name: FELIX_IPINIPMTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # The default IPv4 pool to create on startup if none exists. Pod IPs will be\n            # chosen from this range. Changing this value after installation will have\n            # no effect. This should fall within --cluster-cidr.\n            - name: CALICO_IPV4POOL_CIDR\n              value: \"{{.ClusterCIDR}}\"\n            # Disable file logging so kubectl logs works.\n            - name: CALICO_DISABLE_FILE_LOGGING\n              value: \"true\"\n            # Set Felix endpoint to host default action to ACCEPT.\n            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION\n              value: \"ACCEPT\"\n            # Disable IPv6 on Kubernetes.\n            - name: FELIX_IPV6SUPPORT\n              value: \"false\"\n            # Disable felix logging to file\n            - name: FELIX_LOGFILEPATH\n              value: \"none\"\n            # Disable felix logging for syslog\n            - name: FELIX_LOGSEVERITYSYS\n              value: \"\"\n            # Enable felix logging to stdout\n            - name: FELIX_LOGSEVERITYSCREEN\n              value: \"Warning\"\n            - name: FELIX_HEALTHENABLED\n              value: \"true\"\n          securityContext:\n            privileged: true\n          resources:\n            requests:\n              cpu: 250m\n          livenessProbe:\n            httpGet:\n              path: /liveness\n              port: 9099\n              host: localhost\n            periodSeconds: 10\n            initialDelaySeconds: 10\n            failureThreshold: 6\n          readinessProbe:\n            exec:\n              command:\n              - /bin/calico-node\n              - -bird-ready\n              - -felix-ready\n            periodSeconds: 10\n          volumeMounts:\n            - mountPath: /lib/modules\n              name: lib-modules\n              readOnly: true\n            - mountPath: /run/xtables.lock\n              name: xtables-lock\n              readOnly: false\n            - mountPath: /var/run/calico\n              name: var-run-calico\n              readOnly: false\n            - mountPath: /var/lib/calico\n              name: var-lib-calico\n              readOnly: false\n      volumes:\n        # Used by calico/node.\n        - name: lib-modules\n          hostPath:\n            path: /lib/modules\n        - name: var-run-calico\n          hostPath:\n            path: /var/run/calico\n        - name: var-lib-calico\n          hostPath:\n            path: /var/lib/calico\n        - name: xtables-lock\n          hostPath:\n            path: /run/xtables.lock\n            type: FileOrCreate\n        # Used to install CNI.\n        - name: cni-bin-dir\n          hostPath:\n            path: /opt/cni/bin\n        - name: cni-net-dir\n          hostPath:\n            path: /etc/cni/net.d\n\n# Create all the CustomResourceDefinitions needed for\n# Calico policy and networking mode.\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n   name: felixconfigurations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: FelixConfiguration\n    plural: felixconfigurations\n    singular: felixconfiguration\n\n---\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: bgppeers.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: BGPPeer\n    plural: bgppeers\n    singular: bgppeer\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: bgpconfigurations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: BGPConfiguration\n    plural: bgpconfigurations\n    singular: bgpconfiguration\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ippools.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: IPPool\n    plural: ippools\n    singular: ippool\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: hostendpoints.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: HostEndpoint\n    plural: hostendpoints\n    singular: hostendpoint\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: clusterinformations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: ClusterInformation\n    plural: clusterinformations\n    singular: clusterinformation\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: globalnetworkpolicies.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: GlobalNetworkPolicy\n    plural: globalnetworkpolicies\n    singular: globalnetworkpolicy\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: globalnetworksets.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: GlobalNetworkSet\n    plural: globalnetworksets\n    singular: globalnetworkset\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: networkpolicies.crd.projectcalico.org\nspec:\n  scope: Namespaced\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: NetworkPolicy\n    plural: networkpolicies\n    singular: networkpolicy\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: calico-node\n  namespace: kube-system\n\n\n{{if ne .CloudProvider \"none\"}}\n---\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: {{.CloudProvider}}-ippool\n  namespace: kube-system\ndata:\n  {{.CloudProvider}}-ippool: |-\n    apiVersion: projectcalico.org/v3\n    kind: IPPool\n    metadata:\n      name: ippool-ipip-1\n    spec:\n      cidr: {{.ClusterCIDR}}\n      ipipMode: Always\n      natOutgoing: true\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: calicoctl\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  restartPolicy: OnFailure\n  tolerations:\n  - effect: NoExecute\n    operator: Exists\n  - effect: NoSchedule\n    operator: Exists\n  containers:\n  - name: calicoctl\n    image: {{.Calicoctl}}\n    command: [\"/bin/sh\", \"-c\", \"calicoctl apply -f {{.CloudProvider}}-ippool.yaml\"]\n    env:\n    - name: DATASTORE_TYPE\n      value: kubernetes\n    volumeMounts:\n    - name: ippool-config\n      mountPath: /root/\n  volumes:\n  - name: ippool-config\n    configMap:\n      name: {{.CloudProvider}}-ippool\n      items:\n        - key: {{.CloudProvider}}-ippool\n          path: {{.CloudProvider}}-ippool.yaml\n  # Mount in the etcd TLS secrets.\n{{end}}\n"}