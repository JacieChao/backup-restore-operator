{"apiVersion":"management.cattle.io/v3","kind":"RkeAddon","metadata":{"creationTimestamp":"2020-06-25T21:39:37Z","generation":1,"labels":{"backupper.cattle.io/old-uid":"b5b99910-98a0-4ce8-bf5c-6533f5305c9f","cattle.io/creator":"norman"},"name":"calico-v1.16","namespace":"cattle-global-data","resourceVersion":"2285","selfLink":"/apis/management.cattle.io/v3/namespaces/cattle-global-data/rkeaddons/calico-v1.16"},"template":"\n{{if eq .RBACConfig \"rbac\"}}\n# Source: calico/templates/rbac.yaml\n\n# Include a clusterrole for the kube-controllers component,\n# and bind it to the calico-kube-controllers serviceaccount.\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: calico-kube-controllers\nrules:\n  # Nodes are watched to monitor for deletions.\n  - apiGroups: [\"\"]\n    resources:\n      - nodes\n    verbs:\n      - watch\n      - list\n      - get\n  # Pods are queried to check for existence.\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n    verbs:\n      - get\n  # IPAM resources are manipulated when nodes are deleted.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - ippools\n    verbs:\n      - list\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - blockaffinities\n      - ipamblocks\n      - ipamhandles\n    verbs:\n      - get\n      - list\n      - create\n      - update\n      - delete\n  # Needs access to update clusterinformations.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - clusterinformations\n    verbs:\n      - get\n      - create\n      - update\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: calico-kube-controllers\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: calico-kube-controllers\nsubjects:\n- kind: ServiceAccount\n  name: calico-kube-controllers\n  namespace: kube-system\n---\n# Include a clusterrole for the calico-node DaemonSet,\n# and bind it to the calico-node serviceaccount.\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: calico-node\nrules:\n  # The CNI plugin needs to get pods, nodes, and namespaces.\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - nodes\n      - namespaces\n    verbs:\n      - get\n  - apiGroups: [\"\"]\n    resources:\n      - endpoints\n      - services\n    verbs:\n      # Used to discover service IPs for advertisement.\n      - watch\n      - list\n      # Used to discover Typhas.\n      - get\n  - apiGroups: [\"\"]\n    resources:\n      - nodes/status\n    verbs:\n      # Needed for clearing NodeNetworkUnavailable flag.\n      - patch\n      # Calico stores some configuration information in node annotations.\n      - update\n  # Watch for changes to Kubernetes NetworkPolicies.\n  - apiGroups: [\"networking.k8s.io\"]\n    resources:\n      - networkpolicies\n    verbs:\n      - watch\n      - list\n  # Used by Calico for policy information.\n  - apiGroups: [\"\"]\n    resources:\n      - pods\n      - namespaces\n      - serviceaccounts\n    verbs:\n      - list\n      - watch\n  # The CNI plugin patches pods/status.\n  - apiGroups: [\"\"]\n    resources:\n      - pods/status\n    verbs:\n      - patch\n  # Calico monitors various CRDs for config.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - globalfelixconfigs\n      - felixconfigurations\n      - bgppeers\n      - globalbgpconfigs\n      - bgpconfigurations\n      - ippools\n      - ipamblocks\n      - globalnetworkpolicies\n      - globalnetworksets\n      - networkpolicies\n      - networksets\n      - clusterinformations\n      - hostendpoints\n    verbs:\n      - get\n      - list\n      - watch\n  # Calico must create and update some CRDs on startup.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - ippools\n      - felixconfigurations\n      - clusterinformations\n    verbs:\n      - create\n      - update\n  # Calico stores some configuration information on the node.\n  - apiGroups: [\"\"]\n    resources:\n      - nodes\n    verbs:\n      - get\n      - list\n      - watch\n  # These permissions are only requried for upgrade from v2.6, and can\n  # be removed after upgrade or on fresh installations.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - bgpconfigurations\n      - bgppeers\n    verbs:\n      - create\n      - update\n  # These permissions are required for Calico CNI to perform IPAM allocations.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - blockaffinities\n      - ipamblocks\n      - ipamhandles\n    verbs:\n      - get\n      - list\n      - create\n      - update\n      - delete\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - ipamconfigs\n    verbs:\n      - get\n  # Block affinities must also be watchable by confd for route aggregation.\n  - apiGroups: [\"crd.projectcalico.org\"]\n    resources:\n      - blockaffinities\n    verbs:\n      - watch\n  # The Calico IPAM migration needs to get daemonsets. These permissions can be\n  # removed if not upgrading from an installation using host-local IPAM.\n  - apiGroups: [\"apps\"]\n    resources:\n      - daemonsets\n    verbs:\n      - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: calico-node\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: calico-node\nsubjects:\n- kind: ServiceAccount\n  name: calico-node\n  namespace: kube-system\n- apiGroup: rbac.authorization.k8s.io\n  kind: Group\n  name: system:nodes\n{{end}}\n---\n# Source: calico/templates/calico-config.yaml\n# This ConfigMap is used to configure a self-hosted Calico installation.\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: calico-config\n  namespace: kube-system\ndata:\n  # Typha is disabled.\n  typha_service_name: \"none\"\n  # Configure the backend to use.\n  calico_backend: \"bird\"\n\n  # Configure the MTU to use\n{{- if .MTU }}\n{{- if ne .MTU 0 }}\n  veth_mtu: \"{{.MTU}}\"\n{{- end}}\n{{- else }}\n  veth_mtu: \"1440\"\n{{- end}}\n\n  # The CNI network configuration to install on each node.  The special\n  # values in this config will be automatically populated.\n  cni_network_config: |-\n    {\n      \"name\": \"k8s-pod-network\",\n      \"cniVersion\": \"0.3.1\",\n      \"plugins\": [\n        {\n          \"type\": \"calico\",\n          \"log_level\": \"info\",\n          \"datastore_type\": \"kubernetes\",\n          \"nodename\": \"__KUBERNETES_NODE_NAME__\",\n          \"mtu\": __CNI_MTU__,\n          \"ipam\": {\n              \"type\": \"calico-ipam\"\n          },\n          \"policy\": {\n              \"type\": \"k8s\"\n          },\n          \"kubernetes\": {\n              \"kubeconfig\": \"{{.KubeCfg}}\"\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"snat\": true,\n          \"capabilities\": {\"portMappings\": true}\n        }\n      ]\n    }\n---\n---\n# Source: calico/templates/kdd-crds.yaml\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n   name: felixconfigurations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: FelixConfiguration\n    plural: felixconfigurations\n    singular: felixconfiguration\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ipamblocks.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: IPAMBlock\n    plural: ipamblocks\n    singular: ipamblock\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: blockaffinities.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: BlockAffinity\n    plural: blockaffinities\n    singular: blockaffinity\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ipamhandles.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: IPAMHandle\n    plural: ipamhandles\n    singular: ipamhandle\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ipamconfigs.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: IPAMConfig\n    plural: ipamconfigs\n    singular: ipamconfig\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: bgppeers.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: BGPPeer\n    plural: bgppeers\n    singular: bgppeer\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: bgpconfigurations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: BGPConfiguration\n    plural: bgpconfigurations\n    singular: bgpconfiguration\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: ippools.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: IPPool\n    plural: ippools\n    singular: ippool\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: hostendpoints.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: HostEndpoint\n    plural: hostendpoints\n    singular: hostendpoint\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: clusterinformations.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: ClusterInformation\n    plural: clusterinformations\n    singular: clusterinformation\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: globalnetworkpolicies.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: GlobalNetworkPolicy\n    plural: globalnetworkpolicies\n    singular: globalnetworkpolicy\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: globalnetworksets.crd.projectcalico.org\nspec:\n  scope: Cluster\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: GlobalNetworkSet\n    plural: globalnetworksets\n    singular: globalnetworkset\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: networkpolicies.crd.projectcalico.org\nspec:\n  scope: Namespaced\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: NetworkPolicy\n    plural: networkpolicies\n    singular: networkpolicy\n\n---\n\napiVersion: apiextensions.k8s.io/v1beta1\nkind: CustomResourceDefinition\nmetadata:\n  name: networksets.crd.projectcalico.org\nspec:\n  scope: Namespaced\n  group: crd.projectcalico.org\n  version: v1\n  names:\n    kind: NetworkSet\n    plural: networksets\n    singular: networkset\n---\n---\n# Source: calico/templates/calico-node.yaml\n# This manifest installs the calico-node container, as well\n# as the CNI plugins and network config on\n# each master and worker node in a Kubernetes cluster.\nkind: DaemonSet\napiVersion: apps/v1\nmetadata:\n  name: calico-node\n  namespace: kube-system\n  labels:\n    k8s-app: calico-node\nspec:\n  selector:\n    matchLabels:\n      k8s-app: calico-node\n  updateStrategy:\n{{if .UpdateStrategy}}\n{{ toYaml .UpdateStrategy | indent 4}}\n{{else}}\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n{{end}}\n  template:\n    metadata:\n      labels:\n        k8s-app: calico-node\n      annotations:\n        # This, along with the CriticalAddonsOnly toleration below,\n        # marks the pod as a critical add-on, ensuring it gets\n        # priority scheduling and that its resources are reserved\n        # if it ever gets evicted.\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n      {{ range $k, $v := .NodeSelector }}\n        {{ $k }}: \"{{ $v }}\"\n      {{ end }}\n      hostNetwork: true\n      tolerations:\n        # Make sure calico-node gets scheduled on all nodes.\n        - effect: NoSchedule\n          operator: Exists\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - effect: NoExecute\n          operator: Exists\n          {{if eq .RBACConfig \"rbac\"}}\n      serviceAccountName: calico-node\n          {{end}}\n      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a \"force\n      # deletion\": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.\n      terminationGracePeriodSeconds: 0\n      priorityClassName: system-node-critical\n      initContainers:\n        # This container performs upgrade from host-local IPAM to calico-ipam.\n        # It can be deleted if this is a fresh installation, or if you have already\n        # upgraded to use calico-ipam.\n        - name: upgrade-ipam\n          image: {{.CNIImage}}\n          command: [\"/opt/cni/bin/calico-ipam\", \"-upgrade\"]\n          env:\n            - name: KUBERNETES_NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            - name: CALICO_NETWORKING_BACKEND\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: calico_backend\n          volumeMounts:\n            - mountPath: /var/lib/cni/networks\n              name: host-local-net-dir\n            - mountPath: /host/opt/cni/bin\n              name: cni-bin-dir\n        # This container installs the CNI binaries\n        # and CNI network config file on each node.\n        - name: install-cni\n          image: {{.CNIImage}}\n          command: [\"/install-cni.sh\"]\n          env:\n            # Name of the CNI config file to create.\n            - name: CNI_CONF_NAME\n              value: \"10-calico.conflist\"\n            # The CNI network config to install on each node.\n            - name: CNI_NETWORK_CONFIG\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: cni_network_config\n            # Set the hostname based on the k8s node name.\n            - name: KUBERNETES_NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # CNI MTU Config variable\n            - name: CNI_MTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # Prevents the container from sleeping forever.\n            - name: SLEEP\n              value: \"false\"\n          volumeMounts:\n            - mountPath: /host/opt/cni/bin\n              name: cni-bin-dir\n            - mountPath: /host/etc/cni/net.d\n              name: cni-net-dir\n        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes\n        # to communicate with Felix over the Policy Sync API.\n        - name: flexvol-driver\n          image: {{.FlexVolImg}}\n          volumeMounts:\n          - name: flexvol-driver-host\n            mountPath: /host/driver\n      containers:\n        # Runs calico-node container on each Kubernetes node.  This\n        # container programs network policy and routes on each\n        # host.\n        - name: calico-node\n          image: {{.NodeImage}}\n          env:\n            # Use Kubernetes API as the backing datastore.\n            - name: DATASTORE_TYPE\n              value: \"kubernetes\"\n            # Wait for the datastore.\n            - name: WAIT_FOR_DATASTORE\n              value: \"true\"\n            # Set based on the k8s node name.\n            - name: NODENAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # Choose the backend to use.\n            - name: CALICO_NETWORKING_BACKEND\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: calico_backend\n            # Cluster type to identify the deployment type\n            - name: CLUSTER_TYPE\n              value: \"k8s,bgp\"\n            # Auto-detect the BGP IP address.\n            - name: IP\n              value: \"autodetect\"\n            # Enable IPIP\n            - name: CALICO_IPV4POOL_IPIP\n              value: \"Always\"\n            # Set MTU for tunnel device used if ipip is enabled\n            - name: FELIX_IPINIPMTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # The default IPv4 pool to create on startup if none exists. Pod IPs will be\n            # chosen from this range. Changing this value after installation will have\n            # no effect. This should fall within --cluster-cidr.\n            - name: CALICO_IPV4POOL_CIDR\n              value: \"{{.ClusterCIDR}}\"\n            # Disable file logging so kubectl logs works.\n            - name: CALICO_DISABLE_FILE_LOGGING\n              value: \"true\"\n            # Set Felix endpoint to host default action to ACCEPT.\n            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION\n              value: \"ACCEPT\"\n            # Disable IPv6 on Kubernetes.\n            - name: FELIX_IPV6SUPPORT\n              value: \"false\"\n            # Set Felix logging to \"info\"\n            - name: FELIX_LOGSEVERITYSCREEN\n              value: \"info\"\n            - name: FELIX_HEALTHENABLED\n              value: \"true\"\n          securityContext:\n            privileged: true\n          resources:\n            requests:\n              cpu: 250m\n          livenessProbe:\n            httpGet:\n              path: /liveness\n              port: 9099\n              host: localhost\n            periodSeconds: 10\n            initialDelaySeconds: 10\n            failureThreshold: 6\n          readinessProbe:\n            exec:\n              command:\n              - /bin/calico-node\n              - -bird-ready\n              - -felix-ready\n            periodSeconds: 10\n          volumeMounts:\n            - mountPath: /lib/modules\n              name: lib-modules\n              readOnly: true\n            - mountPath: /run/xtables.lock\n              name: xtables-lock\n              readOnly: false\n            - mountPath: /var/run/calico\n              name: var-run-calico\n              readOnly: false\n            - mountPath: /var/lib/calico\n              name: var-lib-calico\n              readOnly: false\n            - name: policysync\n              mountPath: /var/run/nodeagent\n      volumes:\n        # Used by calico-node.\n        - name: lib-modules\n          hostPath:\n            path: /lib/modules\n        - name: var-run-calico\n          hostPath:\n            path: /var/run/calico\n        - name: var-lib-calico\n          hostPath:\n            path: /var/lib/calico\n        - name: xtables-lock\n          hostPath:\n            path: /run/xtables.lock\n            type: FileOrCreate\n        # Used to install CNI.\n        - name: cni-bin-dir\n          hostPath:\n            path: /opt/cni/bin\n        - name: cni-net-dir\n          hostPath:\n            path: /etc/cni/net.d\n        # Mount in the directory for host-local IPAM allocations. This is\n        # used when upgrading from host-local to calico-ipam, and can be removed\n        # if not using the upgrade-ipam init container.\n        - name: host-local-net-dir\n          hostPath:\n            path: /var/lib/cni/networks\n        # Used to create per-pod Unix Domain Sockets\n        - name: policysync\n          hostPath:\n            type: DirectoryOrCreate\n            path: /var/run/nodeagent\n        # Used to install Flex Volume Driver\n        - name: flexvol-driver-host\n          hostPath:\n            type: DirectoryOrCreate\n{{- if .FlexVolPluginDir }}\n            path: {{.FlexVolPluginDir}}\n{{- else }}\n            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds\n{{- end }}\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: calico-kube-controllers\n  namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: calico-node\n  namespace: kube-system\n---\n# Source: calico/templates/calico-kube-controllers.yaml\n\n# See https://github.com/projectcalico/kube-controllers\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: calico-kube-controllers\n  namespace: kube-system\n  labels:\n    k8s-app: calico-kube-controllers\nspec:\n  # The controllers can only have a single active instance.\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: calico-kube-controllers\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      name: calico-kube-controllers\n      namespace: kube-system\n      labels:\n        k8s-app: calico-kube-controllers\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n      tolerations:\n        # Make sure calico-node gets scheduled on all nodes.\n        - effect: NoSchedule\n          operator: Exists\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - effect: NoExecute\n          operator: Exists\n{{if eq .RBACConfig \"rbac\"}}\n      serviceAccountName: calico-kube-controllers\n{{end}}\n      priorityClassName: system-cluster-critical\n      containers:\n        - name: calico-kube-controllers\n          image: {{.ControllersImage}}\n          env:\n            # Choose which controllers to run.\n            - name: ENABLED_CONTROLLERS\n              value: node\n            - name: DATASTORE_TYPE\n              value: kubernetes\n          readinessProbe:\n            exec:\n              command:\n              - /usr/bin/check-status\n              - -r\n"}